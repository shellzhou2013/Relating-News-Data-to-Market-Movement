{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relating News Data to Market Movement\n",
    "\n",
    "As the efficient-market hypothesis points, asset prices fully reflect all available information. There are three common forms in which the efficient-market hypothesis is commonly stated: weak-form efficiency, semi-strong-form efficiency and strong-form efficiency. The weak-form states that developing trading strategies from public information will not produce excess profits. \n",
    "\n",
    "However, the success of more and more funds prove that implementing trading strategies based on public & private information is able to make money. Public information contains two parts. The first one is commonly used among variety of funds, which is the historical data. The other part, which is a mean to affect people's psychological part and often be neglected, is the public news. However, the second part is a very important part and quantitative analysts seldom pay attention to.\n",
    "\n",
    "In this project, I used machine learning and deep learning methods associated with some nlp methods to build models that links market movement to news data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be found from on github. Check this link: https://github.com/dineshdaultani/StockPredictions/tree/master/Data\n",
    "\n",
    "There are two types of data being gathered over ten years from **2007** to **2016**. \n",
    "\n",
    "The first part is the stock indices. In this data set, DJIA indices of Open, High, Low, Close, Volume and Adjusted Close Price were included. Here, we will use the **Adjusted Close Price** only. The data was collected from Yahoo Finance.\n",
    "\n",
    "The second data contains **News Data** from NY Times Archive API. For the news data, the text was put together to be 1 line for each day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n",
    "In this section, I did some preprocessing for the data. First, I made all the words together. Meantime, I created binary labels for the data. And also train and test data are split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the saved data pickle file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df = pd.read_pickle('/Users/xuhuizhou/Desktop/courses_2019spring/stat541/project/pickled_ten_year_filtered_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-01</th>\n",
       "      <td>12469.971875</td>\n",
       "      <td>12469.971875</td>\n",
       "      <td>. What Sticks from '06. Somalia Orders Islamis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-02</th>\n",
       "      <td>12472.245703</td>\n",
       "      <td>12472.245703</td>\n",
       "      <td>. Heart Health: Vitamin Does Not Prevent Death...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>12474.519531</td>\n",
       "      <td>12474.519531</td>\n",
       "      <td>. Google Answer to Filling Jobs Is an Algorith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>12480.690430</td>\n",
       "      <td>12480.690430</td>\n",
       "      <td>. Helping Make the Shift From Combat to Commer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>12398.009766</td>\n",
       "      <td>12398.009766</td>\n",
       "      <td>. Rise in Ethanol Raises Concerns About Corn a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   close     adj close  \\\n",
       "2007-01-01  12469.971875  12469.971875   \n",
       "2007-01-02  12472.245703  12472.245703   \n",
       "2007-01-03  12474.519531  12474.519531   \n",
       "2007-01-04  12480.690430  12480.690430   \n",
       "2007-01-05  12398.009766  12398.009766   \n",
       "\n",
       "                                                     articles  \n",
       "2007-01-01  . What Sticks from '06. Somalia Orders Islamis...  \n",
       "2007-01-02  . Heart Health: Vitamin Does Not Prevent Death...  \n",
       "2007-01-03  . Google Answer to Filling Jobs Is an Algorith...  \n",
       "2007-01-04  . Helping Make the Shift From Combat to Commer...  \n",
       "2007-01-05  . Rise in Ethanol Raises Concerns About Corn a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>12469.971875</td>\n",
       "      <td>What Sticks from '06. Somalia Orders Islamist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>12472.245703</td>\n",
       "      <td>Heart Health: Vitamin Does Not Prevent Death ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>12474.519531</td>\n",
       "      <td>Google Answer to Filling Jobs Is an Algorithm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>12480.690430</td>\n",
       "      <td>Helping Make the Shift From Combat to Commerc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>12398.009766</td>\n",
       "      <td>Rise in Ethanol Raises Concerns About Corn as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date         price                                           articles\n",
       "0 2007-01-01  12469.971875   What Sticks from '06. Somalia Orders Islamist...\n",
       "1 2007-01-02  12472.245703   Heart Health: Vitamin Does Not Prevent Death ...\n",
       "2 2007-01-03  12474.519531   Google Answer to Filling Jobs Is an Algorithm...\n",
       "3 2007-01-04  12480.690430   Helping Make the Shift From Combat to Commerc...\n",
       "4 2007-01-05  12398.009766   Rise in Ethanol Raises Concerns About Corn as..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'] = df['adj close']\n",
    "df['articles'] = df['articles'].map(lambda x: x.lstrip('.-'))\n",
    "df['date'] = df.index\n",
    "df.reset_index(inplace = True)\n",
    "df = df[['date', 'price', 'articles']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>articles</th>\n",
       "      <th>next_price</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>12469.971875</td>\n",
       "      <td>What Sticks from '06. Somalia Orders Islamist...</td>\n",
       "      <td>12472.245703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>12472.245703</td>\n",
       "      <td>Heart Health: Vitamin Does Not Prevent Death ...</td>\n",
       "      <td>12474.519531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>12474.519531</td>\n",
       "      <td>Google Answer to Filling Jobs Is an Algorithm...</td>\n",
       "      <td>12480.690430</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>12480.690430</td>\n",
       "      <td>Helping Make the Shift From Combat to Commerc...</td>\n",
       "      <td>12398.009766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>12398.009766</td>\n",
       "      <td>Rise in Ethanol Raises Concerns About Corn as...</td>\n",
       "      <td>12406.503255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date         price                                           articles  \\\n",
       "0 2007-01-01  12469.971875   What Sticks from '06. Somalia Orders Islamist...   \n",
       "1 2007-01-02  12472.245703   Heart Health: Vitamin Does Not Prevent Death ...   \n",
       "2 2007-01-03  12474.519531   Google Answer to Filling Jobs Is an Algorithm...   \n",
       "3 2007-01-04  12480.690430   Helping Make the Shift From Combat to Commerc...   \n",
       "4 2007-01-05  12398.009766   Rise in Ethanol Raises Concerns About Corn as...   \n",
       "\n",
       "     next_price  label  \n",
       "0  12472.245703      1  \n",
       "1  12474.519531      1  \n",
       "2  12480.690430      1  \n",
       "3  12398.009766      0  \n",
       "4  12406.503255      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create binary label. When the next day's close price\n",
    "# is higher than today's, we label it 1, otherwise 0\n",
    "df['next_price'] = df['price'].shift(-1)\n",
    "df['label'] = (df['next_price'] > df['price']) * 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the last day's data because there\n",
    "# is no tomorrow for that day in the data\n",
    "df = df[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2922\n",
      "730\n"
     ]
    }
   ],
   "source": [
    "# train and test splitting. 2007-2014 train, 2015-2016 test\n",
    "train = df[df['date'] < '2015-01-01']\n",
    "test = df[df['date'] > '2014-12-31']\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models\n",
    "In this section, multiple models were tested and tuned.\n",
    "### 2.1. Logistic Regression with One Connected Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 54425)\n",
      "Logic Regression 1 accuracy:  0.52602739726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "vectorizer_1 = CountVectorizer()\n",
    "train_1 = vectorizer_1.fit_transform(train['articles'])\n",
    "print(train_1.shape)\n",
    "model_1 = LogisticRegression().fit(train_1, train[\"label\"])\n",
    "test_1 = vectorizer_1.transform(test['articles'])\n",
    "pred_1 = model_1.predict(test_1)\n",
    "acc_1=accuracy_score(test['label'], pred_1)\n",
    "print('Logic Regression 1 accuracy: ',acc_1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49875</th>\n",
       "      <td>0.600179</td>\n",
       "      <td>try</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12111</th>\n",
       "      <td>0.448701</td>\n",
       "      <td>cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18046</th>\n",
       "      <td>0.442023</td>\n",
       "      <td>ferguson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25823</th>\n",
       "      <td>0.441164</td>\n",
       "      <td>john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>0.440137</td>\n",
       "      <td>bay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient      Word\n",
       "49875     0.600179       try\n",
       "12111     0.448701      cuba\n",
       "18046     0.442023  ferguson\n",
       "25823     0.441164      john\n",
       "5093      0.440137       bay"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the words with most and least coefficient\n",
    "basicwords = vectorizer_1.get_feature_names()\n",
    "basiccoeffs = model_1.coef_.tolist()[0]\n",
    "coeffdf = pd.DataFrame({'Word' : basicwords, \n",
    "                        'Coefficient' : basiccoeffs})\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "coeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16832</th>\n",
       "      <td>-0.393243</td>\n",
       "      <td>ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44949</th>\n",
       "      <td>-0.409957</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25363</th>\n",
       "      <td>-0.419106</td>\n",
       "      <td>italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50856</th>\n",
       "      <td>-0.422388</td>\n",
       "      <td>unlikely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12534</th>\n",
       "      <td>-0.430101</td>\n",
       "      <td>danger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient      Word\n",
       "16832    -0.393243    ethics\n",
       "44949    -0.409957  software\n",
       "25363    -0.419106     italy\n",
       "50856    -0.422388  unlikely\n",
       "12534    -0.430101    danger"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Logistic Regression with Two Connected Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 48)\n",
      "Logic Regression 2 accuracy:  0.501369863014\n"
     ]
    }
   ],
   "source": [
    "# find a relative reasonable accuracy\n",
    "vectorizer_2 = TfidfVectorizer( min_df=0.2, max_df=0.95, max_features = 200000, ngram_range = (2, 2))\n",
    "train_2 = vectorizer_2.fit_transform(train['articles'])\n",
    "print(train_2.shape)\n",
    "model_2 = LogisticRegression().fit(train_2, train[\"label\"])\n",
    "test_2 = vectorizer_2.transform(test['articles'])\n",
    "pred_2 = model_2.predict(test_2)\n",
    "acc_2=accuracy_score(test['label'], pred_2)\n",
    "print('Logic Regression 2 accuracy: ', acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.227785</td>\n",
       "      <td>the day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.681015</td>\n",
       "      <td>million in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.574881</td>\n",
       "      <td>north korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.551523</td>\n",
       "      <td>news quiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.374570</td>\n",
       "      <td>plans to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Coefficient         Word\n",
       "37     1.227785      the day\n",
       "21     0.681015   million in\n",
       "25     0.574881  north korea\n",
       "24     0.551523    news quiz\n",
       "30     0.374570     plans to"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the words with most and least coefficient\n",
    "basicwords = vectorizer_2.get_feature_names()\n",
    "basiccoeffs = model_2.coef_.tolist()[0]\n",
    "coeffdf = pd.DataFrame({'Word' : basicwords, \n",
    "                        'Coefficient' : basiccoeffs})\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "coeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.234680</td>\n",
       "      <td>in the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.259136</td>\n",
       "      <td>plan to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.269091</td>\n",
       "      <td>of the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.820618</td>\n",
       "      <td>the early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.033149</td>\n",
       "      <td>daily report</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Coefficient          Word\n",
       "18    -0.234680        in the\n",
       "29    -0.259136       plan to\n",
       "26    -0.269091        of the\n",
       "39    -0.820618     the early\n",
       "5     -1.033149  daily report"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Logistic Regression with Three Connected Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 3217)\n",
      "Logic Regression 3 accuracy:  0.532876712329\n"
     ]
    }
   ],
   "source": [
    "vectorizer_3 = TfidfVectorizer( min_df=0.004, max_df=0.016, max_features = 200000, ngram_range = (3, 3))\n",
    "train_3 = vectorizer_3.fit_transform(train['articles'])\n",
    "print(train_3.shape)\n",
    "model_3 = LogisticRegression().fit(train_3, train[\"label\"])\n",
    "test_3 = vectorizer_3.transform(test['articles'])\n",
    "pred_3 = model_3.predict(test_3)\n",
    "acc_3=accuracy_score(test['label'], pred_3)\n",
    "print('Logic Regression 3 accuracy: ', acc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1.187452</td>\n",
       "      <td>bay area report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1.027108</td>\n",
       "      <td>china moves to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1.023931</td>\n",
       "      <td>business as usual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>1.022957</td>\n",
       "      <td>in northern ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>1.021028</td>\n",
       "      <td>to cut costs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Coefficient                Words\n",
       "273      1.187452      bay area report\n",
       "456      1.027108       china moves to\n",
       "374      1.023931    business as usual\n",
       "1084     1.022957  in northern ireland\n",
       "2750     1.021028         to cut costs"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advwords = vectorizer_3.get_feature_names()\n",
    "advcoeffs = model_3.coef_.tolist()[0]\n",
    "advcoeffdf = pd.DataFrame({'Words' : advwords, \n",
    "                        'Coefficient' : advcoeffs})\n",
    "advcoeffdf = advcoeffdf.sort_values(['Coefficient', 'Words'], ascending=[0, 1])\n",
    "advcoeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>-1.067543</td>\n",
       "      <td>for weather channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>-1.100151</td>\n",
       "      <td>the life report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>-1.109636</td>\n",
       "      <td>world war ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-1.122023</td>\n",
       "      <td>and the future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>-1.240254</td>\n",
       "      <td>back on the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Coefficient                Words\n",
       "772     -1.067543  for weather channel\n",
       "2549    -1.100151      the life report\n",
       "3154    -1.109636         world war ii\n",
       "126     -1.122023       and the future\n",
       "260     -1.240254          back on the"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Naive Bayes with One Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 54399)\n",
      "Naive Bayes 1 accuracy:  0.538356164384\n"
     ]
    }
   ],
   "source": [
    "vectorizer_4 = TfidfVectorizer( min_df=0, max_df=0.8, max_features = 200000, ngram_range = (1, 1))\n",
    "train_4 = vectorizer_4.fit_transform(train['articles'])\n",
    "print(train_4.shape)\n",
    "model_4 = MultinomialNB(alpha=0.01).fit(train_4, train[\"label\"])\n",
    "test_4 = vectorizer_4.transform(test['articles'])\n",
    "pred_4 = model_4.predict(test_4)\n",
    "acc_4=accuracy_score(test['label'], pred_4)\n",
    "print('Naive Bayes 1 accuracy: ', acc_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12730</th>\n",
       "      <td>-6.795260</td>\n",
       "      <td>deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>-6.935432</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40219</th>\n",
       "      <td>-6.973518</td>\n",
       "      <td>report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>-6.973774</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33051</th>\n",
       "      <td>-6.974065</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient   Words\n",
       "12730    -6.795260    deal\n",
       "29590    -6.935432     may\n",
       "40219    -6.973518  report\n",
       "5124     -6.973774      be\n",
       "33051    -6.974065     not"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advwords = vectorizer_4.get_feature_names()\n",
    "advcoeffs = model_4.coef_.tolist()[0]\n",
    "advcoeffdf = pd.DataFrame({'Words' : advwords, \n",
    "                        'Coefficient' : advcoeffs})\n",
    "advcoeffdf = advcoeffdf.sort_values(['Coefficient', 'Words'], ascending=[0, 1])\n",
    "advcoeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54385</th>\n",
       "      <td>-15.007661</td>\n",
       "      <td>تهران</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54392</th>\n",
       "      <td>-15.007661</td>\n",
       "      <td>نه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54393</th>\n",
       "      <td>-15.007661</td>\n",
       "      <td>چندان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54396</th>\n",
       "      <td>-15.007661</td>\n",
       "      <td>中国的不法</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54398</th>\n",
       "      <td>-15.007661</td>\n",
       "      <td>总理家人隐秘的财富</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient      Words\n",
       "54385   -15.007661      تهران\n",
       "54392   -15.007661         نه\n",
       "54393   -15.007661      چندان\n",
       "54396   -15.007661      中国的不法\n",
       "54398   -15.007661  总理家人隐秘的财富"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Naive Bayes with Two Connected Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 323)\n",
      "Naive Bayes 2 accuracy:  0.523287671233\n"
     ]
    }
   ],
   "source": [
    "vectorizer_5 = TfidfVectorizer( min_df=0.07, max_df=0.25, max_features = 200000, ngram_range = (2, 2))\n",
    "train_5 = vectorizer_5.fit_transform(train['articles'])\n",
    "print(train_5.shape)\n",
    "model_5 = MultinomialNB(alpha=0.001)\n",
    "model_5 = model_5.fit(train_5, train[\"label\"])\n",
    "test_5 = vectorizer_5.transform(test['articles'])\n",
    "pred_5 = model_5.predict(test_5)\n",
    "acc_5 = accuracy_score(test['label'], pred_5)\n",
    "print('Naive Bayes 2 accuracy: ', acc_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-5.059054</td>\n",
       "      <td>north korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-5.087397</td>\n",
       "      <td>hedge fund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-5.204116</td>\n",
       "      <td>the new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-5.205317</td>\n",
       "      <td>bank of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.230265</td>\n",
       "      <td>about the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficient        Words\n",
       "138    -5.059054  north korea\n",
       "76     -5.087397   hedge fund\n",
       "234    -5.204116      the new\n",
       "21     -5.205317      bank of\n",
       "0      -5.230265    about the"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advwords = vectorizer_5.get_feature_names()\n",
    "advcoeffs = model_5.coef_.tolist()[0]\n",
    "advcoeffdf = pd.DataFrame({'Words' : advwords, \n",
    "                        'Coefficient' : advcoeffs})\n",
    "advcoeffdf = advcoeffdf.sort_values(['Coefficient', 'Words'], ascending=[0, 1])\n",
    "advcoeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-6.227342</td>\n",
       "      <td>people of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-6.232397</td>\n",
       "      <td>with new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-6.237200</td>\n",
       "      <td>and its</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>-6.250869</td>\n",
       "      <td>to start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-6.261136</td>\n",
       "      <td>note in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficient      Words\n",
       "166    -6.227342  people of\n",
       "318    -6.232397   with new\n",
       "8      -6.237200    and its\n",
       "285    -6.250869   to start\n",
       "141    -6.261136    note in"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Random Forest with One Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 2906)\n",
      "Random Forest 1 accuracy:  0.530136986301\n"
     ]
    }
   ],
   "source": [
    "vectorizer_6 = TfidfVectorizer( min_df=0.04, max_df=0.6, max_features = 200000, ngram_range = (1, 1))\n",
    "train_6 = vectorizer_6.fit_transform(train['articles'])\n",
    "print(train_6.shape)\n",
    "model_6 = RandomForestClassifier(random_state = 12345).fit(train_6, train[\"label\"])\n",
    "test_6 = vectorizer_6.transform(test['articles'])\n",
    "pred_6 = model_6.predict(test_6)\n",
    "acc_6 = accuracy_score(test['label'], pred_6)\n",
    "print('Random Forest 1 accuracy: ', acc_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Random Forest with Two Connected Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 590)\n",
      "Random Forest 2 accuracy:  0.53698630137\n"
     ]
    }
   ],
   "source": [
    "vectorizer_7 = TfidfVectorizer( min_df=0.05, max_df=0.28, max_features = 200000, ngram_range = (2, 2))\n",
    "train_7 = vectorizer_7.fit_transform(train['articles'])\n",
    "print(train_7.shape)\n",
    "model_7 = RandomForestClassifier(random_state = 12345).fit(train_7, train[\"label\"])\n",
    "test_7 = vectorizer_7.transform(test['articles'])\n",
    "pred_7 = model_7.predict(test_7)\n",
    "acc_7 = accuracy_score(test['label'], pred_7)\n",
    "print('Random Forest 2 accuracy: ', acc_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Gradient Boost Machine with One Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 2397)\n",
      "Gradient Boost Machine 1 accuracy:  0.541095890411\n"
     ]
    }
   ],
   "source": [
    "vectorizer_8 = TfidfVectorizer( min_df=0.05, max_df=0.75, \n",
    "                                             max_features = 200000, ngram_range = (1, 1))\n",
    "train_8 = vectorizer_8.fit_transform(train['articles'])\n",
    "print(train_8.shape)\n",
    "model_8 = GradientBoostingClassifier(random_state = 12345).fit(train_8, train[\"label\"])\n",
    "test_8 = vectorizer_8.transform(test['articles'])\n",
    "pred_8 = model_8.predict(test_8.toarray())\n",
    "acc_8 = accuracy_score(test['label'], pred_8)\n",
    "print('Gradient Boost Machine 1 accuracy: ', acc_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9. Gradient Boost Machine with Two Connected Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 315)\n",
      "Gradient Boost Machine 2 accuracy:  0.554794520548\n"
     ]
    }
   ],
   "source": [
    "vectorizer_9 = TfidfVectorizer( min_df=0.07, max_df=0.21, \n",
    "                                             max_features = 200000, ngram_range = (2, 2))\n",
    "train_9 = vectorizer_9.fit_transform(train['articles'])\n",
    "print(train_9.shape)\n",
    "model_9 = GradientBoostingClassifier(random_state=12345).fit(train_9, train[\"label\"])\n",
    "test_9 = vectorizer_9.transform(test['articles'])\n",
    "pred_9 = model_9.predict(test_9.toarray())\n",
    "acc_9 = accuracy_score(test['label'], pred_9)\n",
    "print('Gradient Boost Machine 2 accuracy: ', acc_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10. Stochastic Gradient Descent Classifier with One Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 7647)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuhuizhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent Classifier 1 accuracy:  0.535616438356\n"
     ]
    }
   ],
   "source": [
    "vectorizer_10 = TfidfVectorizer( min_df=0.01, max_df=0.75,\n",
    "                                             max_features = 200000, ngram_range = (1, 1))\n",
    "train_10 = vectorizer_10.fit_transform(train['articles'])\n",
    "print(train_10.shape)\n",
    "model_10 = SGDClassifier(loss='modified_huber', n_iter=5, random_state=12345, shuffle=True)\n",
    "model_10 = model_10.fit(train_10, train[\"label\"])\n",
    "test_10 = vectorizer_10.transform(test['articles'])\n",
    "pred_10 = model_10.predict(test_10.toarray())\n",
    "acc_10 = accuracy_score(test['label'], pred_10)\n",
    "print('Stochastic Gradient Descent Classifier 1 accuracy: ', acc_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11. Stochastic Gradient Descent Classifier with Two Connected Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 127)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuhuizhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent Classifier 1 accuracy:  0.532876712329\n"
     ]
    }
   ],
   "source": [
    "vectorizer_11 = TfidfVectorizer( min_df=0.09, max_df=0.15, \n",
    "                                             max_features = 200000, ngram_range = (2, 2))\n",
    "train_11 = vectorizer_11.fit_transform(train['articles'])\n",
    "print(train_11.shape)\n",
    "model_11 = SGDClassifier(loss='modified_huber', n_iter=5, random_state=12345, shuffle=True)\n",
    "model_11 = model_11.fit(train_11, train[\"label\"])\n",
    "test_11 = vectorizer_11.transform(test['articles'])\n",
    "pred_11 = model_11.predict(test_11.toarray())\n",
    "acc_11 = accuracy_score(test['label'], pred_11)\n",
    "print('Stochastic Gradient Descent Classifier 1 accuracy: ', acc_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.12. Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 107)\n",
      "X_train shape: (2922, 107)\n",
      "X_test shape: (730, 107)\n",
      "Training...\n",
      "Train on 2483 samples, validate on 439 samples\n",
      "Epoch 1/2\n",
      "2483/2483 [==============================] - 3s 1ms/step - loss: 0.6937 - val_loss: 0.6959\n",
      "Epoch 2/2\n",
      "2483/2483 [==============================] - 0s 160us/step - loss: 0.6871 - val_loss: 0.6984\n",
      "Generating test predictions...\n",
      "prediction accuracy:  0.486301369863\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_classes = 2\n",
    "vectorizer_12 = TfidfVectorizer( min_df=0.13, max_df=0.54, max_features = 200000, ngram_range = (2, 2))\n",
    "train_12 = vectorizer_12.fit_transform(train['articles'])\n",
    "test_12 = vectorizer_12.transform(test['articles'])\n",
    "print(train_12.shape)\n",
    "\n",
    "X_train = train_12.toarray()\n",
    "X_test = test_12.toarray()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "y_train = np.array(train[\"label\"])\n",
    "y_test = np.array(test[\"label\"])\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "# pre-processing: divide by max and substract mean\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale\n",
    "\n",
    "mean = np.mean(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Here's a Deep Dumb MLP (DDMLP)\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=input_dim))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# we'll use categorical xent for the loss, and RMSprop as the optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "print(\"Training...\")\n",
    "model.fit(X_train, Y_train, epochs=2, batch_size=16, validation_split=0.15)\n",
    "\n",
    "print(\"Generating test predictions...\")\n",
    "pred_12 = model.predict_classes(X_test, verbose=0)\n",
    "acc_12 = accuracy_score(test[\"label\"], pred_12)\n",
    "\n",
    "print('prediction accuracy: ', acc_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.13. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (2922, 200)\n",
      "X_test shape: (730, 200)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 2922 samples, validate on 730 samples\n",
      "Epoch 1/3\n",
      "2922/2922 [==============================] - 26s 9ms/step - loss: 0.6927 - acc: 0.5260 - val_loss: 0.6933 - val_acc: 0.5082\n",
      "Epoch 2/3\n",
      "2922/2922 [==============================] - 22s 8ms/step - loss: 0.6292 - acc: 0.6773 - val_loss: 0.7723 - val_acc: 0.5041\n",
      "Epoch 3/3\n",
      "2922/2922 [==============================] - 22s 8ms/step - loss: 0.3519 - acc: 0.8593 - val_loss: 1.0385 - val_acc: 0.4877\n",
      "730/730 [==============================] - 1s 2ms/step\n",
      "Test score: 1.03852928354\n",
      "Test accuracy: 0.48767123255\n",
      "Generating test predictions...\n",
      "prediction accuracy:  0.487671232877\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.1\n",
    "maxlen = 200\n",
    "batch_size = 32\n",
    "nb_classes = 2\n",
    "\n",
    "# vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "train_13 = train['articles']\n",
    "tokenizer.fit_on_texts(train_13)\n",
    "train_13 = tokenizer.texts_to_sequences(train_13)\n",
    "test_13 = tokenizer.texts_to_sequences(test['articles'])\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(train_13, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(test_13, maxlen=maxlen)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(keras.layers.SpatialDropout1D(rate = 0.2))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2)) \n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=3,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score, acc = model.evaluate(X_test, Y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "\n",
    "print(\"Generating test predictions...\")\n",
    "pred_15 = model.predict_classes(X_test, verbose=0)\n",
    "acc_15 = accuracy_score(test['label'], pred_15)\n",
    "\n",
    "print('prediction accuracy: ', acc_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In section 2, I tried variety of models in machine learning and deep learning. All models give accuracy of about 0.5, which is not good. \n",
    "I have spoken with some friends in CS department who are doing research with NLP. They told me that they've tried to extract signals from financial data with nlp methods. However, the signal is so weak that, once using large dataset, it is averaged and disappeared. \n",
    "I think that is reasonable if they are using a general collection of words such as from NLTK. If we want to find signals from news data to predict stock price, we need to build a very related collection of words.\n",
    "Will try some more NLP methods in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
